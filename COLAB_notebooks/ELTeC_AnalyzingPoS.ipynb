{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELTeC_AnalyzingPoS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6cn4LtLXYGPIkeBeCQFZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bncolorado/Processing-ELTeC-corpus/blob/main/COLAB_notebooks/ELTeC_AnalyzingPoS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9YAgkI8Naco"
      },
      "source": [
        "# Extracting part of speech from ELTeC-SPA\n",
        "\n",
        "Borja Navarro Colorado | Unviersidad de Alicante\n",
        "\n",
        "In this case, the information about part of speech has not been manually annotated in the corpus. It is necessary first analyze the novels with a NLP system and then extract the linguistic information. The NLP system used is [SpaCy](https://spacy.io/).\n",
        "\n",
        "The notebook shows:\n",
        "\n",
        "- how to open a novel from ELTeC in COLAB,\n",
        "- how to activate SpaCy in COLAB,\n",
        "- how to analyze the novel with SpaCy, and\n",
        "- how to extract information about Part of Speec.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2j6tERTNTcP"
      },
      "source": [
        "## Loading ELTeC-SPA corpus in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kejn4RdANZEy"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "!wget \"https://github.com/COST-ELTeC/ELTeC-spa/archive/refs/heads/master.zip\" # paste here corpus url\n",
        "\n",
        "zip_ref = zipfile.ZipFile('master.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts files here (/content/)\n",
        "zip_ref.close() \n",
        "!rm master.zip #Removes ZIP to save space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLkW02KoOIX6"
      },
      "source": [
        "## SpaCy: download and installing\n",
        "\n",
        "[SpaCy](https://spacy.io/) is a NLP system. It analyzes part of speech and lemmas, sintax (dependencies) and named entities. \n",
        "\n",
        "Three steps:\n",
        "\n",
        "1. Import SpaCy to Colab\n",
        "2. Download langauge module (Spanish)\n",
        "3. Activate module\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNHMbKkERXhI"
      },
      "source": [
        "import spacy\n",
        "\n",
        "!python -m spacy download es_core_news_sm #Download Spanish module (the \"small\" module in this case: \"sm\").\n",
        "\n",
        "import es_core_news_sm\n",
        "nlp_esp = es_core_news_sm.load() #Load Spanish analyzer in \"nlp_esp\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsk-hIbqRuw5"
      },
      "source": [
        "## Analyzing a novel from ELTeC-SPA\n",
        "\n",
        "Once we have downloaded the corpus and activated SpaCy, let's analyze one novel.\n",
        "\n",
        "First, select from the corpus [ELTeC-SPA](https://github.com/COST-ELTeC/ELTeC-spa/tree/master/level1) a novel and copy the file name. Then paste the name in the variable \"novela_name\". In this example, we will analyze the novel of Gertrudis GÃ³mez de Avellaneda [*Sab*](https://github.com/COST-ELTeC/ELTeC-spa/blob/master/level1/SPA1021_GomezDeAvellaneda_Sab.xml): SPA1021_GomezDeAvellaneda_Sab.xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJtGl9vRzpq"
      },
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "novela_name = \"SPA1021_GomezDeAvellaneda_Sab.xml\" # Put here the name of the file\n",
        "dir_in = \"/content/ELTeC-spa-master/level1/\"\n",
        "\n",
        "novela_text = '' \n",
        "\n",
        "print('Analyzing', novela_name)\n",
        "\n",
        "ficheroEntrada = dir_in + novela_name\n",
        "with open(ficheroEntrada, 'r') as tei: #Opens the file\n",
        "  print(\"Opening the file and extracting text\")\n",
        "  soup = BeautifulSoup(tei, 'xml') #Parse the XML\n",
        "  capitulos = soup.find_all(type=\"chapter\") #Only chapters are taking into account. No letters (To Do)\n",
        "  for cap in capitulos:\n",
        "    parrafos = cap.find_all('p') #Extract all paragraphs of each chapter\n",
        "    for parrafo in parrafos:\n",
        "      #print(parrafo.text)\n",
        "      novela_text+=parrafo.text+'\\n'\n",
        "\n",
        "print('Analyzing PoS and lemmas')\n",
        "analisis = nlp_esp(novela_text) #Here the novel is analyzed with SpaCy. All the analysis is stored in \"analisis\" variable.\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_13VKGg9A7Z"
      },
      "source": [
        "Now all the analysis is stored in \"analisis\" variable. It only remains to iterate over the variable and extract the information: in this case, part of speech. How to extract information about syntax, named entities, etc. see [SpaCy 101](https://spacy.io/usage/spacy-101)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Zqf9ZC6-0N"
      },
      "source": [
        "NVA = '\\tNovel\\tNouns\\tVerbs\\tAdjectives\\n' #\n",
        "\n",
        "nom_novela = 'Sab'\n",
        "#nom_novela = novela_name\n",
        "\n",
        "nouns=[]\n",
        "verbs=[]\n",
        "adjs=[]\n",
        "\n",
        "for token in analisis: \n",
        "  if token.pos_ == 'NOUN':\n",
        "    nouns.append(token.lemma_) #\n",
        "  elif token.pos_ == 'VERB':\n",
        "    verbs.append(token.lemma_) #\n",
        "  elif token.pos_ == 'ADJ':\n",
        "    adjs.append(token.lemma_) #\n",
        "\n",
        "num_nouns = str(len(nouns))\n",
        "num_verbs = str(len(verbs))\n",
        "num_adjs = str(len(adjs))\n",
        "\n",
        "NVA += '\\t'+nom_novela+'\\t'+num_nouns+'\\t'+num_verbs+'\\t'+num_adjs+'\\n' #\n",
        "\n",
        "print(NVA)\n",
        "\n",
        "#salida = open('analisis_soloNombres.txt', 'w') #Crea fichero, etc.\n",
        "#salida.write(corpus_soloNombres)\n",
        "#salida.close()\n",
        "#files.download('analisis_soloNombres.txt')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}